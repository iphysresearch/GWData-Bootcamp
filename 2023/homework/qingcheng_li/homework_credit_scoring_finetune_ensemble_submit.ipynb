{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一起来打怪之 Credit Scoring 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## >>>说明：\n",
    "### 1. 答题步骤：\n",
    "- 回答问题**请保留每一步**操作过程，请不要仅仅给出最后答案\n",
    "- 请养成代码注释的好习惯\n",
    "\n",
    "### 2. 解题思路：\n",
    "- 为方便大家准确理解题目，在习题实战中有所收获，本文档提供了解题思路提示\n",
    "- 解题思路**仅供参考**，鼓励原创解题方法\n",
    "- 为督促同学们自己思考，解题思路内容设置为**注释**，请注意查看\n",
    "\n",
    "### 3. 所用数据：\n",
    "- 问题使用了多个数据库，请注意导入每个数据库后都先**查看和了解数据的基本性质**，后面的问题不再一一提醒"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## 操作题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信用卡欺诈项目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 前期数据导入,预览及处理(此部分勿修改，涉及的数据文件无需复制移动)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines   age  \\\n",
       "0                 1                              0.766127  45.0   \n",
       "1                 0                              0.957151  40.0   \n",
       "2                 0                              0.658180  38.0   \n",
       "3                 0                              0.233810  30.0   \n",
       "4                 0                              0.907239  49.0   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                   2.0   0.802982         9120.0   \n",
       "1                                   0.0   0.121876         2600.0   \n",
       "2                                   1.0   0.085113         3042.0   \n",
       "3                                   0.0   0.036050         3300.0   \n",
       "4                                   1.0   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                             13.0                      0.0   \n",
       "1                              4.0                      0.0   \n",
       "2                              2.0                      1.0   \n",
       "3                              5.0                      0.0   \n",
       "4                              7.0                      0.0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                           6.0                                   0.0   \n",
       "1                           0.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           0.0                                   0.0   \n",
       "4                           1.0                                   0.0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 2.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import zipfile\n",
    "with zipfile.ZipFile('KaggleCredit2.csv.zip', 'r') as z:\n",
    "    f = z.open('KaggleCredit2.csv')\n",
    "    data = pd.read_csv(f, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112915, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查数据维度\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs                           0\n",
       "RevolvingUtilizationOfUnsecuredLines       0\n",
       "age                                     4267\n",
       "NumberOfTime30-59DaysPastDueNotWorse       0\n",
       "DebtRatio                                  0\n",
       "MonthlyIncome                              0\n",
       "NumberOfOpenCreditLinesAndLoans            0\n",
       "NumberOfTimes90DaysLate                    0\n",
       "NumberRealEstateLoansOrLines               0\n",
       "NumberOfTime60-89DaysPastDueNotWorse       0\n",
       "NumberOfDependents                      4267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据缺失值情况\n",
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 清除缺失值\n",
    "data.dropna(inplace=True)\n",
    "data.shapey = data['SeriousDlqin2yrs']\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06742876076872101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取出对应的X和y\n",
    "y = data['SeriousDlqin2yrs']\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)\n",
    "# 查看平均的欺诈率\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下为操作题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.把数据切分成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76053, 10), (32595, 10), (76053,), (32595,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提示：查看train_test_split函数\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    101322\n",
      "1      7326\n",
      "Name: SeriousDlqin2yrs, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f25a233fe90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 通过SeriousDlqin2yrs字段查看正负样本分布情况\n",
    "# 提示：value_counts\n",
    "class_distribution = data['SeriousDlqin2yrs'].value_counts()\n",
    "print(class_distribution)\n",
    "\n",
    "# 绘制两种类别的柱状图\n",
    "# 提示：dataframe可以直接plot(kind='bar')\n",
    "class_distribution.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.数据预处理之离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 请对年龄按照3岁一个区间进行离散化\n",
    "# 提示：可以先计算出分桶边界，再基于pandas的cut函数进行离散化(分箱、分桶)\n",
    "data['age'] = data['age'].astype(int)\n",
    "bin_edges = list(range(0, data['age'].max() + 4, 3))\n",
    "\n",
    "# 使用 cut 函数进行离散化\n",
    "data['age_group'] = pd.cut(data['age'], bins=bin_edges, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.数据预处理之独热向量编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
      "0                      1                              0.766127   45   \n",
      "1                      0                              0.957151   40   \n",
      "2                      0                              0.658180   38   \n",
      "3                      0                              0.233810   30   \n",
      "4                      0                              0.907239   49   \n",
      "...                  ...                                   ...  ...   \n",
      "112910                 0                              0.385742   50   \n",
      "112911                 0                              0.040674   74   \n",
      "112912                 0                              0.299745   44   \n",
      "112913                 0                              0.000000   30   \n",
      "112914                 0                              0.850283   64   \n",
      "\n",
      "        NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
      "0                                        2.0   0.802982         9120.0   \n",
      "1                                        0.0   0.121876         2600.0   \n",
      "2                                        1.0   0.085113         3042.0   \n",
      "3                                        0.0   0.036050         3300.0   \n",
      "4                                        1.0   0.024926        63588.0   \n",
      "...                                      ...        ...            ...   \n",
      "112910                                   0.0   0.404293         3400.0   \n",
      "112911                                   0.0   0.225131         2100.0   \n",
      "112912                                   0.0   0.716562         5584.0   \n",
      "112913                                   0.0   0.000000         5716.0   \n",
      "112914                                   0.0   0.249908         8158.0   \n",
      "\n",
      "        NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
      "0                                  13.0                      0.0   \n",
      "1                                   4.0                      0.0   \n",
      "2                                   2.0                      1.0   \n",
      "3                                   5.0                      0.0   \n",
      "4                                   7.0                      0.0   \n",
      "...                                 ...                      ...   \n",
      "112910                              7.0                      0.0   \n",
      "112911                              4.0                      0.0   \n",
      "112912                              4.0                      0.0   \n",
      "112913                              4.0                      0.0   \n",
      "112914                              8.0                      0.0   \n",
      "\n",
      "        NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
      "0                                6.0                                   0.0   \n",
      "1                                0.0                                   0.0   \n",
      "2                                0.0                                   0.0   \n",
      "3                                0.0                                   0.0   \n",
      "4                                1.0                                   0.0   \n",
      "...                              ...                                   ...   \n",
      "112910                           0.0                                   0.0   \n",
      "112911                           1.0                                   0.0   \n",
      "112912                           1.0                                   0.0   \n",
      "112913                           0.0                                   0.0   \n",
      "112914                           2.0                                   0.0   \n",
      "\n",
      "        NumberOfDependents age_group  \n",
      "0                      2.0  [45, 48)  \n",
      "1                      1.0  [39, 42)  \n",
      "2                      0.0  [36, 39)  \n",
      "3                      0.0  [30, 33)  \n",
      "4                      0.0  [48, 51)  \n",
      "...                    ...       ...  \n",
      "112910                 0.0  [48, 51)  \n",
      "112911                 0.0  [72, 75)  \n",
      "112912                 2.0  [42, 45)  \n",
      "112913                 0.0  [30, 33)  \n",
      "112914                 0.0  [63, 66)  \n",
      "\n",
      "[108648 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# 请对上述分箱后的年龄段进行独热向量编码\n",
    "# 提示：使用pandas的get_dummies完成\n",
    "one_hot_encoded = pd.get_dummies(data['age_group'], prefix='age_group')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.数据预处理之幅度缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 请对连续值特征进行幅度缩放\n",
    "# 提示：可以使用StandardScaler等幅度缩放器进行处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.使用logistic regression建模，并且输出一下系数，分析重要度。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01428306, -0.36429905,  1.72891212,  0.31210456, -0.11519947,\n",
       "        -0.09188154,  1.68980927, -0.19642882, -3.24878873,  0.11639217]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提示：fit建模，建完模之后可以取出coef属性\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr = LogisticRegression(C=1000.0, max_iter=100, random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_std)\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.使用网格搜索交叉验证进行调参\n",
    "调整penalty和C参数，其中penalty候选为\"l1\"和\"l2\"，C的候选为[1,10,100,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# 提示：先按照上面要求准备好网格字典，再使用GridSearchCV进行调参\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {'penalty': ['l1', 'l2'], 'C': [1, 10, 100, 500]}\n",
    "\n",
    "# 创建 GridSearchCV 对象\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.93233666        nan 0.93233666        nan 0.93231037\n",
      "        nan 0.93234981]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 500, 'penalty': 'l2'}\n",
      "Best Model Accuracy: 0.9332106151250191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# 输出最好的超参数\n",
    "# 输出最好的模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 获取最佳参数\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# 使用最佳参数的模型在测试集上进行预测\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "# 计算准确率\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.在测试集上进行预测，计算 查准率/查全率/auc/混淆矩阵/f1值 等测试指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9332106151250191\n",
      "Precision: 0.4673913043478261\n",
      "Recall: 0.019806540764624597\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[30375    49]\n",
      " [ 2128    43]]\n",
      "F1 Score: 0.03800265134776845\n"
     ]
    }
   ],
   "source": [
    "# 提示：在测试集上预测可以使用predict\n",
    "# 提示：各种指标可以在sklearn.metrics中查到各种评估指标，分别是accuracy_score、recall_score、auc、confusion_matrix、f1_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix, f1_score,precision_score\n",
    "# 在测试集上进行预测\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "# 计算各种指标\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)  # 假设 y_pred_proba 是模型的概率预测值\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# 打印结果\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.更多优化\n",
    "银行通常会有更严格的要求，因为欺诈带来的后果通常比较严重，一般我们会调整模型的标准。   \n",
    "\n",
    "比如在logistic regression当中，一般我们的概率判定边界为0.5，但是我们可以把阈值设定低一些，来提高模型的“敏感度”   \n",
    "试试看把阈值设定为0.3，再看看这个时候的混淆矩阵等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold: 0.1\n",
      "Accuracy: 0.7456051541647492\n",
      "Precision: 0.12443244569885875\n",
      "Recall: 0.46706586826347307\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[23289  7135]\n",
      " [ 1157  1014]]\n",
      "F1 Score: 0.19651162790697677\n",
      "\n",
      "Threshold: 0.2\n",
      "Accuracy: 0.9153857953673876\n",
      "Precision: 0.2768060836501901\n",
      "Recall: 0.16766467065868262\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[29473   951]\n",
      " [ 1807   364]]\n",
      "F1 Score: 0.20883534136546184\n",
      "\n",
      "Threshold: 0.3\n",
      "Accuracy: 0.930756250958736\n",
      "Precision: 0.3903061224489796\n",
      "Recall: 0.07047443574389682\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[30185   239]\n",
      " [ 2018   153]]\n",
      "F1 Score: 0.11939133827545845\n",
      "\n",
      "Threshold: 0.4\n",
      "Accuracy: 0.932750421843841\n",
      "Precision: 0.43558282208588955\n",
      "Recall: 0.0327038231229848\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[30332    92]\n",
      " [ 2100    71]]\n",
      "F1 Score: 0.060839760068551844\n",
      "\n",
      "Threshold: 0.5\n",
      "Accuracy: 0.9332106151250191\n",
      "Precision: 0.4673913043478261\n",
      "Recall: 0.019806540764624597\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[30375    49]\n",
      " [ 2128    43]]\n",
      "F1 Score: 0.03800265134776845\n",
      "\n",
      "Threshold: 0.6\n",
      "Accuracy: 0.9333640128854118\n",
      "Precision: 0.49122807017543857\n",
      "Recall: 0.012897282358360202\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[30395    29]\n",
      " [ 2143    28]]\n",
      "F1 Score: 0.02513464991023339\n",
      "\n",
      "Threshold: 0.7\n",
      "Accuracy: 0.9334560515416475\n",
      "Precision: 0.5263157894736842\n",
      "Recall: 0.009212344541685858\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[30406    18]\n",
      " [ 2151    20]]\n",
      "F1 Score: 0.01810774105930285\n",
      "\n",
      "Threshold: 0.8\n",
      "Accuracy: 0.933425371989569\n",
      "Precision: 0.5172413793103449\n",
      "Recall: 0.006909258406264394\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[30410    14]\n",
      " [ 2156    15]]\n",
      "F1 Score: 0.013636363636363636\n",
      "\n",
      "Threshold: 0.9\n",
      "Accuracy: 0.933486731093726\n",
      "Precision: 0.8\n",
      "Recall: 0.0018424689083371719\n",
      "AUC: 0.6796832466259455\n",
      "Confusion Matrix:\n",
      " [[30423     1]\n",
      " [ 2167     4]]\n",
      "F1 Score: 0.0036764705882352945\n"
     ]
    }
   ],
   "source": [
    "# 提示：thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "# 根据predict_proba的结果和threshold的比较确定结果，再评估各种结果指标\n",
    "# 在测试集上进行预测和获取概率值\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 设定不同的阈值\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# 遍历每个阈值，计算并输出各种指标\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_threshold)\n",
    "    precision = precision_score(y_test, y_pred_threshold)\n",
    "    recall = recall_score(y_test, y_pred_threshold)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_threshold)\n",
    "    f1 = f1_score(y_test, y_pred_threshold)\n",
    "\n",
    "    print(f\"\\nThreshold: {threshold}\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"AUC:\", auc)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.尝试对不同特征的重要度进行排序，通过特征选择的方式，对特征进行筛选。并重新建模，观察此时的模型准确率等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with selected features: 0.9339162448228255\n"
     ]
    }
   ],
   "source": [
    "# 可以根据逻辑回归的系数绝对值大小进行排序，也可以基于树模型的特征重要度进行排序\n",
    "# 特征选择可以使用RFE或者selectFromModel\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 使用逻辑回归模型进行特征选择\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, n_features_to_select=5)  \n",
    "X_train_selected = rfe.fit_transform(X_train, y_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# 训练新的模型\n",
    "model_selected = LogisticRegression()\n",
    "model_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# 在测试集上进行预测和评估\n",
    "y_pred_selected = model_selected.predict(X_test_selected)\n",
    "accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
    "print(\"Accuracy with selected features:\", accuracy_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.其他模型算法尝试\n",
    "使用RandomForestClassifier/SVM/KNN等sklearn分类算法进行分类，尝试上述超参数调优算法过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 支持向量机\n",
    "from sklearn.svm import SVC\n",
    "# K最近邻\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#好像要花的时间有点久\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 创建随机森林模型\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# 使用GridSearchCV进行超参数搜索\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search_rf.best_params_)\n",
    "\n",
    "# 在测试集上进行预测和评估\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy with Random Forest:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
